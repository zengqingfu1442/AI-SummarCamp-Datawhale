{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手把手打一场NLP赛事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言处理（Natural Language Processing，NLP）是指计算机处理和理解人类语言的技术。NLP涵盖了从文本的基本语法和词汇处理到更高级的任务，如机器翻译、情感分析、问答系统等。NLP利用计算机算法和模型，对文本进行分词、词性标注、句法分析等处理，以便将人类语言转化为计算机可以理解和处理的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 赛题信息\n",
    "医学领域的文献库中蕴含了丰富的疾病诊断和治疗信息，如何高效地从海量文献中提取关键信息，进行疾病诊断和治疗推荐，对于临床医生和研究人员具有重要意义。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于论文摘要的文本分类与关键词抽取挑战赛  \n",
    "https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper&ch=ymfk4uU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/bc8c545638eb4200a68836ed741b6fe7d75108e9009d443b8de5b33fb8e0fa55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.准备步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 赛事报名\n",
    "赛事地址：https://challenge.xfyun.cn/topic/info?type=abstract-of-the-paper&ch=ZuoaKcY\n",
    "1. 点击报名参赛，登录讯飞开放平台。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据下载\n",
    "数据已提前下载在数据集目录下，您可以自行查看其中的train与test文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 环境配置参考资料\n",
    "python环境的搭建请参考：\n",
    "- [Mac设备：Mac上安装Anaconda最全教程](https://zhuanlan.zhihu.com/p/350828057)\n",
    "- [Windows设备：Anaconda超详细安装教程(Windows环境下)_菜鸟1号!!的博客-CSDN博客_windows安装anaconda](https://blog.csdn.net/fan18317517352/article/details/123035625)\n",
    "Jupyter 编辑器的使用请参考：\n",
    "- [Jupyter Notebook最全使用教程，看这篇就够了！](https://www.jianshu.com/p/6cc047bc94e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 赛题解析\n",
    "实践任务\n",
    "本任务分为两个子任务：\n",
    "1. 从论文标题、摘要作者等信息，判断该论文是否属于医学领域的文献。\n",
    "2. 从论文标题、摘要作者等信息，提取出该论文关键词。\n",
    "\n",
    "第一个任务看作是一个文本二分类任务。机器需要根据对论文摘要等信息的理解，将论文划分为医学领域的文献和非医学领域的文献两个类别之一。第二个任务看作是一个文本关键词识别任务。机器需要从给定的论文中识别和提取出与论文内容相关的关键词。  \n",
    "\n",
    "**本次学习中我们仅学习第一个任务**  \n",
    "\n",
    "数据集解析\n",
    "训练集与测试集数据为CSV格式文件，各字段分别是标题、作者和摘要。Keywords为任务2的标签，label为任务1的标签。训练集和测试集都可以通过pandas读取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/8c88537bce9d46049151389396c4c5b828556ba332d34ed3a24555e4e28e7191)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.实践思路&baseline\n",
    "### 实践思路\n",
    "本赛题任务主要如下：\n",
    "1. 从论文标题、摘要作者等信息，判断该论文是否属于医学领域的文献。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务一：文本二分类\n",
    "第一个任务看作是一个文本二分类任务。机器需要根据对论文摘要等信息的理解，将论文划分为医学领域的文献和非医学领域的文献两个类别之一。\n",
    "\n",
    "针对文本分类任务，可以提供两种实践思路，一种是使用传统的特征提取方法（如TF-IDF/BOW）结合机器学习模型，另一种是使用预训练的BERT模型进行建模。使用特征提取 + 机器学习的思路步骤如下：\n",
    "1. 数据预处理：首先，对文本数据进行预处理，包括文本清洗（如去除特殊字符、标点符号）、分词等操作。可以使用常见的NLP工具包（如NLTK或spaCy）来辅助进行预处理。\n",
    "2. 特征提取：使用TF-IDF（词频-逆文档频率）或BOW（词袋模型）方法将文本转换为向量表示。TF-IDF可以计算文本中词语的重要性，而BOW则简单地统计每个词语在文本中的出现次数。可以使用scikit-learn库的TfidfVectorizer或CountVectorizer来实现特征提取。\n",
    "3. 构建训练集和测试集：将预处理后的文本数据分割为训练集和测试集，确保数据集的样本分布均匀。\n",
    "4. 选择机器学习模型：根据实际情况选择适合的机器学习模型，如朴素贝叶斯、支持向量机（SVM）、随机森林等。这些模型在文本分类任务中表现良好。可以使用scikit-learn库中相应的分类器进行模型训练和评估。\n",
    "5. 模型训练和评估：使用训练集对选定的机器学习模型进行训练，然后使用测试集进行评估。评估指标可以选择准确率、精确率、召回率、F1值等。\n",
    "6. 调参优化：如果模型效果不理想，可以尝试调整特征提取的参数（如词频阈值、词袋大小等）或机器学习模型的参数，以获得更好的性能。  \n",
    "\n",
    "\n",
    "Baseline中我们选择使用BOW将文本转换为向量表示，选择逻辑回归模型来完成训练和评估  \n",
    "代码演示如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T05:23:20.613491Z",
     "iopub.status.busy": "2023-08-18T05:23:20.612570Z",
     "iopub.status.idle": "2023-08-18T05:23:22.414224Z",
     "shell.execute_reply": "2023-08-18T05:23:22.413227Z",
     "shell.execute_reply.started": "2023-08-18T05:23:20.613455Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk) (8.1.6)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk) (1.3.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk) (2023.8.8)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.10/site-packages (from nltk) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "# 获取前置依赖\n",
    "!pip install nltk -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T05:23:22.416531Z",
     "iopub.status.busy": "2023-08-18T05:23:22.415918Z",
     "iopub.status.idle": "2023-08-18T05:23:34.026276Z",
     "shell.execute_reply": "2023-08-18T05:23:34.025264Z",
     "shell.execute_reply.started": "2023-08-18T05:23:22.416503Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入pandas用于读取表格数据\n",
    "import pandas as pd\n",
    "\n",
    "# 导入BOW（词袋模型），可以选择将CountVectorizer替换为TfidfVectorizer（TF-IDF（词频-逆文档频率）），注意上下文要同时修改，亲测后者效果更佳\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 导入LogisticRegression回归模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 过滤警告消息\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# 读取数据集\n",
    "train = pd.read_csv('/home/aistudio/data/data231041/train.csv')\n",
    "train['title'] = train['title'].fillna('')\n",
    "train['abstract'] = train['abstract'].fillna('')\n",
    "\n",
    "test = pd.read_csv('/home/aistudio/data/data231041/testB.csv')\n",
    "test['title'] = test['title'].fillna('')\n",
    "test['abstract'] = test['abstract'].fillna('')\n",
    "\n",
    "\n",
    "# 提取文本特征，生成训练集与测试集\n",
    "train['text'] = train['title'].fillna('') + ' ' +  train['author'].fillna('') + ' ' + train['abstract'].fillna('')+ ' ' + train['Keywords'].fillna('')\n",
    "test['text'] = test['title'].fillna('') + ' ' +  test['author'].fillna('') + ' ' + test['abstract'].fillna('')\n",
    "\n",
    "#vector = CountVectorizer().fit(train['text'])\n",
    "vector = TfidfVectorizer().fit(train['text'])\n",
    "train_vector = vector.transform(train['text'])\n",
    "test_vector = vector.transform(test['text'])\n",
    "\n",
    "\n",
    "# 引入模型\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 开始训练，这里可以考虑修改默认的batch_size与epoch来取得更好的效果\n",
    "model.fit(train_vector, train['label'])\n",
    "\n",
    "# 利用模型对测试集label标签进行预测\n",
    "test['label'] = model.predict(test_vector)\n",
    "test['Keywords'] = test['title'].fillna('')\n",
    "test[['uuid','Keywords','label']].to_csv('submit_task1.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整baseline运行后任务一分数在0.67116左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
